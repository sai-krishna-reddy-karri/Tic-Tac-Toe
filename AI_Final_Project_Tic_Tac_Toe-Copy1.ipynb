{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b96ad44d",
   "metadata": {},
   "source": [
    "# Implementation of Tic-Tac-Toe with a human against Min-Max AI agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d25b625",
   "metadata": {},
   "source": [
    "To play the game, simply run the code below and follow the instructions in the terminal. The AI will use the Min-Max algorithm to determine its moves, and the player will be prompted to enter their moves using the keyboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd9ae6d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to Tic-Tac-Toe!\n",
      "  |   |  \n",
      "---------\n",
      "  |   |  \n",
      "---------\n",
      "  |   |  \n",
      "AI is making a move...\n",
      "O |   |  \n",
      "---------\n",
      "  |   |  \n",
      "---------\n",
      "  |   |  \n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def draw_board(board):\n",
    "    print(board[0], \"|\", board[1], \"|\", board[2])\n",
    "    print(\"---------\")\n",
    "    print(board[3], \"|\", board[4], \"|\", board[5])\n",
    "    print(\"---------\")\n",
    "    print(board[6], \"|\", board[7], \"|\", board[8])\n",
    "\n",
    "def get_player_move(board):\n",
    "    valid_move = False\n",
    "    while not valid_move:\n",
    "        move = input(\"Enter your move (0-8): \")\n",
    "        if move.isdigit() and int(move) >= 0 and int(move) <= 8 and board[int(move)] == \" \":\n",
    "            valid_move = True\n",
    "        else:\n",
    "            print(\"Invalid move, try again.\")\n",
    "    return int(move)\n",
    "\n",
    "def get_ai_move(board):\n",
    "    best_score = -float(\"inf\")\n",
    "    best_move = None\n",
    "    for i in range(9):\n",
    "        if board[i] == \" \":\n",
    "            board[i] = \"O\"\n",
    "            score = min_max(board, False)\n",
    "            board[i] = \" \"\n",
    "            if score > best_score:\n",
    "                best_score = score\n",
    "                best_move = i\n",
    "    return best_move\n",
    "\n",
    "def min_max(board, is_maximizing):\n",
    "    if check_winner(board):\n",
    "        if is_maximizing:\n",
    "            return -1\n",
    "        else:\n",
    "            return 1\n",
    "    elif check_tie(board):\n",
    "        return 0\n",
    "    elif is_maximizing:\n",
    "        best_score = -float(\"inf\")\n",
    "        for i in range(9):\n",
    "            if board[i] == \" \":\n",
    "                board[i] = \"O\"\n",
    "                score = min_max(board, False)\n",
    "                board[i] = \" \"\n",
    "                if score > best_score:\n",
    "                    best_score = score\n",
    "        return best_score\n",
    "    else:\n",
    "        best_score = float(\"inf\")\n",
    "        for i in range(9):\n",
    "            if board[i] == \" \":\n",
    "                board[i] = \"X\"\n",
    "                score = min_max(board, True)\n",
    "                board[i] = \" \"\n",
    "                if score < best_score:\n",
    "                    best_score = score\n",
    "        return best_score\n",
    "\n",
    "def check_winner(board):\n",
    "    for i in range(3):\n",
    "        if board[i] != \" \" and board[i] == board[i + 3] and board[i] == board[i + 6]:\n",
    "            return True\n",
    "    for i in range(0, 9, 3):\n",
    "        if board[i] != \" \" and board[i] == board[i + 1] and board[i] == board[i + 2]:\n",
    "            return True\n",
    "    if board[0] != \" \" and board[0] == board[4] and board[0] == board[8]:\n",
    "        return True\n",
    "    if board[2] != \" \" and board[2] == board[4] and board[2] == board[6]:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def check_tie(board):\n",
    "    return not \" \" in board\n",
    "\n",
    "\n",
    "def play_game():\n",
    "    board = [\" \" for _ in range(9)]\n",
    "    player_turn = random.choice([True, False])\n",
    "    print(\"Welcome to Tic-Tac-Toe!\")\n",
    "    draw_board(board)\n",
    "    while True:\n",
    "        if player_turn:\n",
    "            move = get_player_move(board)\n",
    "            board[move] = \"X\"\n",
    "        else:\n",
    "            print(\"AI is making a move...\")\n",
    "            move = get_ai_move(board)\n",
    "            board[move] = \"O\"\n",
    "        draw_board(board)\n",
    "        if check_winner(board):\n",
    "            if player_turn:\n",
    "                print(\"Congratulations! You win!\")\n",
    "            else:\n",
    "                print(\"Sorry, the AI wins.\")\n",
    "            break\n",
    "        elif check_tie(board):\n",
    "            print(\"It's a tie!\")\n",
    "            break\n",
    "        player_turn = not player_turn\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    play_game()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "993226f5",
   "metadata": {},
   "source": [
    "#### Explanation:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d9c634",
   "metadata": {},
   "source": [
    "The implementation uses the minimax algorithm to determine the optimal move for the computer player. The minimax algorithm is a recursive function that explores all possible game states and selects the move that leads to the best outcome for the computer player. The computer player is represented by the \"O\" symbol.\n",
    "\n",
    "The code defines several functions:\n",
    "\n",
    "draw_board: prints the current state of the game board to the console.\n",
    "\n",
    "get_player_move: prompts the human player to enter their move, validates the input, and returns the selected move as an integer.\n",
    "\n",
    "get_ai_move: uses the minimax algorithm to select the optimal move for the computer player and returns the selected move as an integer.\n",
    "\n",
    "min_max(board, is_maximizing): the recursive function that implements the minimax algorithm. Returns the score of the current game state, with positive scores indicating a winning position for the computer player, negative scores indicating a winning position for the human player, and zero indicating a tie.\n",
    "\n",
    "check_winner: checks if either player has won the game by examining all possible winning combinations of cells.\n",
    "\n",
    "check_tie: checks if the game is a tie by checking if all cells are filled.\n",
    "\n",
    "Finally, the code defines the play_game() function that initializes the game board, randomly selects the starting player, and loops through each turn until a winner is determined or the game ends in a tie. The game state is printed to the console after each turn, and the winner is announced at the end of the game. The __name__ == \"__main__\" check at the end of the code ensures that the game is only played if the code is run as a standalone program and not imported as a module."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d25cca8",
   "metadata": {},
   "source": [
    "## Implementation of a Tic-Tac-Toe game by a human against an AI agent using Alpha-Beta pruning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8b908140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to Tic-Tac-Toe!\n",
      "  |   |  \n",
      "---------\n",
      "  |   |  \n",
      "---------\n",
      "  |   |  \n",
      "AI is making a move...\n",
      "O |   |  \n",
      "---------\n",
      "  |   |  \n",
      "---------\n",
      "  |   |  \n",
      "Enter your move (0-8): 3\n",
      "O |   |  \n",
      "---------\n",
      "X |   |  \n",
      "---------\n",
      "  |   |  \n",
      "AI is making a move...\n",
      "O | O |  \n",
      "---------\n",
      "X |   |  \n",
      "---------\n",
      "  |   |  \n",
      "Enter your move (0-8): 4\n",
      "O | O |  \n",
      "---------\n",
      "X | X |  \n",
      "---------\n",
      "  |   |  \n",
      "AI is making a move...\n",
      "O | O | O\n",
      "---------\n",
      "X | X |  \n",
      "---------\n",
      "  |   |  \n",
      "Sorry, the AI wins.\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "def draw_board(board):\n",
    "    print(board[0], \"|\", board[1], \"|\", board[2])\n",
    "    print(\"---------\")\n",
    "    print(board[3], \"|\", board[4], \"|\", board[5])\n",
    "    print(\"---------\")\n",
    "    print(board[6], \"|\", board[7], \"|\", board[8])\n",
    "\n",
    "def get_player_move(board):\n",
    "    valid_move = False\n",
    "    while not valid_move:\n",
    "        move = input(\"Enter your move (0-8): \")\n",
    "        if move.isdigit() and int(move) in range(9) and board[int(move)] == \" \":\n",
    "            return int(move)\n",
    "        else:\n",
    "            print(\"Invalid move, please try again.\")\n",
    "\n",
    "def check_winner(board):\n",
    "    winning_positions = [\n",
    "        (0, 1, 2), (3, 4, 5), (6, 7, 8),\n",
    "        (0, 3, 6), (1, 4, 7), (2, 5, 8),\n",
    "        (0, 4, 8), (2, 4, 6)\n",
    "    ]\n",
    "    for a, b, c in winning_positions:\n",
    "        if board[a] == board[b] == board[c] != \" \":\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def check_tie(board):\n",
    "    return \" \" not in board\n",
    "\n",
    "def get_ai_move(board):\n",
    "    _, move = minimax(board, True, -float(\"inf\"), float(\"inf\"))\n",
    "    return move\n",
    "\n",
    "def minimax(board, is_maximizing_player, alpha, beta):\n",
    "    if check_winner(board):\n",
    "        return (-1 if is_maximizing_player else 1, None)\n",
    "    elif check_tie(board):\n",
    "        return (0, None)\n",
    "\n",
    "    if is_maximizing_player:\n",
    "        best_score = -float(\"inf\")\n",
    "        for i in range(9):\n",
    "            if board[i] == \" \":\n",
    "                board[i] = \"O\"\n",
    "                score, _ = minimax(board, False, alpha, beta)\n",
    "                board[i] = \" \"\n",
    "                if score > best_score:\n",
    "                    best_score = score\n",
    "                    best_move = i\n",
    "                alpha = max(alpha, best_score)\n",
    "                if beta <= alpha:\n",
    "                    break\n",
    "        return (best_score, best_move)\n",
    "    else:\n",
    "        best_score = float(\"inf\")\n",
    "        for i in range(9):\n",
    "            if board[i] == \" \":\n",
    "                board[i] = \"X\"\n",
    "                score, _ = minimax(board, True, alpha, beta)\n",
    "                board[i] = \" \"\n",
    "                if score < best_score:\n",
    "                    best_score = score\n",
    "                    best_move = i\n",
    "                beta = min(beta, best_score)\n",
    "                if beta <= alpha:\n",
    "                    break\n",
    "        return (best_score, best_move)\n",
    "\n",
    "\n",
    "def play_game():\n",
    "    board = [\" \" for _ in range(9)]\n",
    "    player_turn = random.choice([True, False])\n",
    "    print(\"Welcome to Tic-Tac-Toe!\")\n",
    "    draw_board(board)\n",
    "    while True:\n",
    "        if player_turn:\n",
    "            move = get_player_move(board)\n",
    "            board[move] = \"X\"\n",
    "        else:\n",
    "            print(\"AI is making a move...\")\n",
    "            move = get_ai_move(board)\n",
    "            board[move] = \"O\"\n",
    "        draw_board(board)\n",
    "        if check_winner(board):\n",
    "            if player_turn:\n",
    "                print(\"Congratulations! You win!\")\n",
    "            else:\n",
    "                print(\"Sorry, the AI wins.\")\n",
    "            break\n",
    "        elif check_tie(board):\n",
    "            print(\"It's a tie!\")\n",
    "            break\n",
    "        player_turn = not player_turn\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    play_game()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8c4c783",
   "metadata": {},
   "source": [
    "## Explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9771acb",
   "metadata": {},
   "source": [
    "The code starts by importing the random module which will be used to randomly determine which player goes first.\n",
    "\n",
    "The draw_board function takes in a list representing the current state of the board and prints it out in a readable format.\n",
    "\n",
    "The get_player_move function prompts the user for input until a valid move is entered, then returns the chosen move. A valid move is an integer between 0 and 8 (inclusive) that corresponds to an empty square on the board.\n",
    "\n",
    "The check_winner function checks the board to see if any player has won. It does this by checking all possible winning combinations on the board (i.e., rows, columns, and diagonals). If any of these combinations contain three of the same symbol (X or O), the function returns True. Otherwise, it returns False.\n",
    "\n",
    "The check_tie function checks the board to see if the game has ended in a tie. This is true when there are no empty squares left on the board.\n",
    "\n",
    "The get_ai_move function uses the minimax algorithm to determine the best move for the AI player. The minimax algorithm is a recursive function that simulates all possible moves on the board and chooses the move that results in the best outcome for the AI player. The function returns the score associated with the chosen move, as well as the index of the chosen move.\n",
    "\n",
    "The minimax function is called recursively to simulate all possible moves on the board. It takes in the current board state, a boolean value indicating whether the current player is maximizing or minimizing (i.e., the AI or the human player), and two parameters, alpha and beta, that are used to prune the search tree and improve the algorithm's efficiency. The function returns the best score and the index of the best move.\n",
    "\n",
    "The play_game function initializes an empty board and randomly determines which player goes first. It then loops through each turn, prompting the human player for input or calling get_ai_move to determine the AI's move. After each turn, the board is redrawn and the check_winner and check_tie functions are called to determine if the game has ended. If so, the winner (or lack thereof) is announced and the game ends. If not, the loop continues with the other player's turn.\n",
    "\n",
    "Finally, the if __name__ == \"__main__\" line at the bottom of the code ensures that play_game is only called if the script is run directly (i.e., not imported as a module)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64f89c62",
   "metadata": {},
   "source": [
    "## Implementation of a Tic-Tac-Toe with a human against an AI agent using Q-learning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7a7eb014",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current state:\n",
      "[[0 0 0]\n",
      " [0 0 0]\n",
      " [0 0 0]]\n",
      "Enter row and column (0-2): 2\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 2, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 78\u001b[0m\n\u001b[0;32m     76\u001b[0m \u001b[38;5;66;03m#row, col = input(\"Enter row and column (0-2): \").split()\u001b[39;00m\n\u001b[0;32m     77\u001b[0m input_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;28minput\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEnter row and column (0-2): \u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 78\u001b[0m row, col \u001b[38;5;241m=\u001b[39m input_str\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m input_str \u001b[38;5;28;01melse\u001b[39;00m input_str\u001b[38;5;241m.\u001b[39msplit()\n\u001b[0;32m     79\u001b[0m row, col \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(row), \u001b[38;5;28mint\u001b[39m(col)\n\u001b[0;32m     80\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m state[row][col] \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "\u001b[1;31mValueError\u001b[0m: not enough values to unpack (expected 2, got 1)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Initialize Q-values\n",
    "Q = {}\n",
    "\n",
    "# Hyperparameters\n",
    "alpha = 0.1 # learning rate\n",
    "gamma = 0.9 # discount factor\n",
    "epsilon = 0.1 # exploration probability\n",
    "\n",
    "# Define game state and action space\n",
    "state_space = [[0, 0, 0] for i in range(3)]\n",
    "action_space = [(i, j) for i in range(3) for j in range(3)]\n",
    "\n",
    "# Define reward function\n",
    "def reward(state):\n",
    "    if any(sum(row) == 3 for row in state): # check rows\n",
    "        return 1\n",
    "    if any(sum(col) == 3 for col in zip(*state)): # check columns\n",
    "        return 1\n",
    "    if sum(state[i][i] for i in range(3)) == 3: # check diagonal\n",
    "        return 1\n",
    "    if sum(state[i][2-i] for i in range(3)) == 3: # check diagonal\n",
    "        return 1\n",
    "    if any(sum(row) == -3 for row in state): # check rows\n",
    "        return -1\n",
    "    if any(sum(col) == -3 for col in zip(*state)): # check columns\n",
    "        return -1\n",
    "    if sum(state[i][i] for i in range(3)) == -3: # check diagonal\n",
    "        return -1\n",
    "    if sum(state[i][2-i] for i in range(3)) == -3: # check diagonal\n",
    "        return -1\n",
    "    return 0\n",
    "\n",
    "# Define epsilon-greedy policy\n",
    "def epsilon_greedy_policy(state, epsilon):\n",
    "    if random.uniform(0, 1) < epsilon:\n",
    "        return random.choice(action_space)\n",
    "    else:\n",
    "        #q_values = [Q.get((tuple(state), action), 0) for action in action_space]\n",
    "        q_values = [Q.get((tuple(map(tuple, state)), action), 0) for action in action_space]\n",
    "        max_q_value = max(q_values)\n",
    "        count = q_values.count(max_q_value)\n",
    "        if count > 1:\n",
    "            best_actions = [action_space[i] for i in range(len(action_space)) if q_values[i] == max_q_value]\n",
    "            return random.choice(best_actions)\n",
    "        else:\n",
    "            return action_space[q_values.index(max_q_value)]\n",
    "\n",
    "# Define Q-learning algorithm\n",
    "#def q_learning(state, action, next_state, reward, alpha, gamma):\n",
    "#   max_next_q_value = max([Q.get((tuple(next_state), next_action), 0) for next_action in action_space])\n",
    "#   current_q_value = Q.get((tuple(state), action), 0)\n",
    "#    Q[(tuple(state), action)] = current_q_value + alpha * (reward + gamma * max_next_q_value - current_q_value)\n",
    "    \n",
    "def q_learning(state, action, next_state, reward, alpha, gamma):\n",
    "    state = tuple(map(tuple, state))\n",
    "    next_state = tuple(map(tuple, next_state))\n",
    "    # Get Q-value for current state-action pair\n",
    "    q_value = Q.get((state, action), 0)\n",
    "    # Compute the maximum Q-value for the next state\n",
    "    #max_q_value = max([Q.get((next_state, a), 0) for a in action_space(next_state)])\n",
    "    max_q_value = max([Q.get((next_state, a), 0) for a in action_space])\n",
    "    # Update Q-value using Q-learning formula\n",
    "    #Q[(state, action)] = q_value + alpha * (reward + gamma * max_q_value - q_value)\n",
    "    Q[tuple(map(tuple, state)), action] = q_value + alpha * (reward + gamma * max_q_value - q_value)\n",
    "\n",
    "\n",
    "# Initialize game\n",
    "state = state_space.copy()\n",
    "while True:\n",
    "    # Human player's turn\n",
    "    print(\"Current state:\")\n",
    "    print(np.array(state))\n",
    "    #row, col = input(\"Enter row and column (0-2): \").split()\n",
    "    input_str = input(\"Enter row and column (0-2): \")\n",
    "    row, col = input_str.split('-') if '-' in input_str else input_str.split()\n",
    "    row, col = int(row), int(col)\n",
    "    if state[row][col] != 0:\n",
    "        print(\"Invalid move, try again.\")\n",
    "        continue\n",
    "    state[row][col] = 1\n",
    "    reward_value = reward(state)\n",
    "    if reward_value != 0:\n",
    "        print(\"You won!\")\n",
    "        break\n",
    "    if all(all(row) for row in state):\n",
    "        print(\"Tie!\")\n",
    "        break\n",
    "    # AI agent's turn\n",
    "    action = epsilon_greedy_policy(state, epsilon)\n",
    "    state[action[0]][action[1]] = -1\n",
    "    reward_value = reward(state)\n",
    "    \n",
    "    if reward_value != 0:\n",
    "        print(\"You lost!\")\n",
    "        break\n",
    "    if all(all(row) for row in state):\n",
    "        print(\"Tie!\")\n",
    "        break\n",
    "\n",
    "# Update Q-values\n",
    "q_learning(state, action, state, reward_value, alpha, gamma)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b38a9e1",
   "metadata": {},
   "source": [
    "## Explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "388c7390",
   "metadata": {},
   "source": [
    "The program starts by defining some variables and functions:\n",
    "\n",
    "Q: a dictionary that will store the Q-values for state-action pairs\n",
    "alpha: the learning rate\n",
    "gamma: the discount factor\n",
    "epsilon: the exploration probability\n",
    "state_space: a list that represents the state of the game board\n",
    "action_space: a list that represents all possible actions\n",
    "reward(state): a function that computes the reward for a given state\n",
    "epsilon_greedy_policy(state, epsilon): a function that implements the epsilon-greedy policy for selecting actions\n",
    "q_learning(state, action, next_state, reward, alpha, gamma): a function that updates the Q-value for a given state-action pair\n",
    "The program then initializes the game board and starts a loop where the human player and the AI agent take turns making moves.\n",
    "\n",
    "During the human player's turn, the program prints the current state of the game board and prompts the user to enter the row and column of their move. If the move is valid, the program updates the game board and checks if the game is over. If the game is over, the program prints the result and exits the loop.\n",
    "\n",
    "During the AI agent's turn, the program uses the epsilon-greedy policy to select an action, updates the game board, and checks if the game is over. If the game is over, the program prints the result and exits the loop.\n",
    "\n",
    "After the game is over, the program calls the q_learning() function to update the Q-value for the last state-action pair."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ca9aaae",
   "metadata": {},
   "source": [
    "## Implementing TIC-TAC-TOE using all AI Agents (MIN_MAX, ALPHA_BETA, Q-LEARNING)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e4ff600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================================\n",
      "TIC-TAC-TOE using MINIMAX with MIN MAX OVER ALPHA-BETA Pruning\n",
      "=================================================\n",
      "|   ||   ||   |\n",
      "---------------\n",
      "|   || X ||   |\n",
      "---------------\n",
      "|   ||   ||   |\n",
      "---------------\n",
      "===============\n",
      "| O ||   ||   |\n",
      "---------------\n",
      "|   || X ||   |\n",
      "---------------\n",
      "|   ||   ||   |\n",
      "---------------\n",
      "===============\n",
      "| O || O ||   |\n",
      "---------------\n",
      "|   || X ||   |\n",
      "---------------\n",
      "|   ||   ||   |\n",
      "---------------\n",
      "===============\n",
      "| O || O || X |\n",
      "---------------\n",
      "|   || X ||   |\n",
      "---------------\n",
      "|   ||   ||   |\n",
      "---------------\n",
      "===============\n",
      "| O || O || X |\n",
      "---------------\n",
      "|   || X ||   |\n",
      "---------------\n",
      "| O ||   ||   |\n",
      "---------------\n",
      "===============\n",
      "| O || O || X |\n",
      "---------------\n",
      "| O || X ||   |\n",
      "---------------\n",
      "| O ||   ||   |\n",
      "---------------\n",
      "===============\n",
      "O's have won!, Alpha Beta Pruning  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from random import choice\n",
    "from math import inf\n",
    "\n",
    "board = [[0, 0, 0],\n",
    "         [0, 0, 0],\n",
    "         [0, 0, 0]]\n",
    "\n",
    "def Gameboard(board):\n",
    "    chars = {1: 'X', -1: 'O', 0: ' '}\n",
    "    for x in board:\n",
    "        for y in x:\n",
    "            ch = chars[y]\n",
    "            print(f'| {ch} |', end='')\n",
    "        print('\\n' + '---------------')\n",
    "    print('===============')\n",
    "\n",
    "def Clearboard(board):\n",
    "    for x, row in enumerate(board):\n",
    "        for y, col in enumerate(row):\n",
    "            board[x][y] = 0\n",
    "\n",
    "def winningPlayer(board, player):\n",
    "    conditions = [[board[0][0], board[0][1], board[0][2]],\n",
    "                     [board[1][0], board[1][1], board[1][2]],\n",
    "                     [board[2][0], board[2][1], board[2][2]],\n",
    "                     [board[0][0], board[1][0], board[2][0]],\n",
    "                     [board[0][1], board[1][1], board[2][1]],\n",
    "                     [board[0][2], board[1][2], board[2][2]],\n",
    "                     [board[0][0], board[1][1], board[2][2]],\n",
    "                     [board[0][2], board[1][1], board[2][0]]]\n",
    "\n",
    "    if [player, player, player] in conditions:\n",
    "        return True\n",
    "\n",
    "    return False\n",
    "\n",
    "def gameWon(board):\n",
    "    return winningPlayer(board, 1) or winningPlayer(board, -1)\n",
    "\n",
    "def printResult(board):\n",
    "    if winningPlayer(board, 1):\n",
    "        print('X has won!, Min Max  ' + '\\n')\n",
    "\n",
    "    elif winningPlayer(board, -1):\n",
    "        print('O\\'s have won!, Alpha Beta Pruning  ' + '\\n')\n",
    "\n",
    "    else:\n",
    "        print('Draw' + '\\n')\n",
    "\n",
    "def blanks(board):\n",
    "    blank = []\n",
    "    for x, row in enumerate(board):\n",
    "        for y, col in enumerate(row):\n",
    "            if board[x][y] == 0:\n",
    "                blank.append([x, y])\n",
    "\n",
    "    return blank\n",
    "\n",
    "def boardFull(board):\n",
    "    if len(blanks(board)) == 0:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def setMove(board, x, y, player):\n",
    "    board[x][y] = player\n",
    "\n",
    "def playerMove(board):\n",
    "    e = True\n",
    "    moves = {1: [0, 0], 2: [0, 1], 3: [0, 2],\n",
    "             4: [1, 0], 5: [1, 1], 6: [1, 2],\n",
    "             7: [2, 0], 8: [2, 1], 9: [2, 2]}\n",
    "    while e:\n",
    "        try:\n",
    "            move = int(input('Enter a number between 1-9: '))\n",
    "            if move < 1 or move > 9:\n",
    "                print('Invalid Move! Try again!')\n",
    "            elif not (moves[move] in blanks(board)):\n",
    "                print('Invalid Move! Try again!')\n",
    "            else:\n",
    "                setMove(board, moves[move][0], moves[move][1], 1)\n",
    "                Gameboard(board)\n",
    "                e = False\n",
    "        except(KeyError, ValueError):\n",
    "            print('Enter a number!')\n",
    "\n",
    "def getScore(board):\n",
    "    if winningPlayer(board, 1):\n",
    "        return 10\n",
    "\n",
    "    elif winningPlayer(board, -1):\n",
    "        return -10\n",
    "\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "    \n",
    "class QLearningPlayer():\n",
    "    def __init__(self):\n",
    "        self.name = 'Q-Learning'\n",
    "        self.q = {}\n",
    "        self.init_q = 1 # \"optimistic\" 1.0 initial values\n",
    "        self.lr = 0.3\n",
    "        self.gamma = 0.9\n",
    "        self.epsilon = 1.0\n",
    "        self.max_epsilon = 1.0\n",
    "        self.min_epsilon = 0.01\n",
    "        self.decay_rate = 0.01\n",
    "        self.action_n = 9\n",
    "        self.win_n = 0\n",
    "\n",
    "        self.last_state = (' ',) * 9\n",
    "        self.last_action = -1\n",
    "\n",
    "    def action(self, state, actions):\n",
    "        state = tuple(state)\n",
    "        self.last_state = state\n",
    "\n",
    "        r = random.uniform(0, 1)\n",
    "        if r > self.epsilon:\n",
    "            if self.q.get(state):\n",
    "                i = np.argmax([self.q[state][a] for a in actions])\n",
    "                action = actions[i]\n",
    "            else:\n",
    "                self.q[state] = [self.init_q] * self.action_n\n",
    "                action = random.choice(actions)\n",
    "        else:\n",
    "            action = random.choice(actions)\n",
    "\n",
    "        self.last_action = action\n",
    "        return action\n",
    "\n",
    "    def reward(self, reward, state):\n",
    "        if self.last_action >= 0:\n",
    "            if reward == 1:\n",
    "                self.win_n += 1\n",
    "\n",
    "            state = tuple(state)\n",
    "            if self.q.get(self.last_state):\n",
    "                q = self.q[self.last_state][self.last_action]\n",
    "            else:\n",
    "                self.q[self.last_state] = [self.init_q] * self.action_n\n",
    "                q = self.init_q\n",
    "\n",
    "            self.q[self.last_state][self.last_action] = q + self.lr * (reward + self.gamma * np.max(self.q.get(state, [self.init_q]*self.action_n)) - q)\n",
    "\n",
    "    def episode_end(self, episode):\n",
    "        # epsilon decay\n",
    "        self.epsilon = self.min_epsilon + (self.max_epsilon - self.min_epsilon) * np.exp(-self.decay_rate*(episode+1))\n",
    "\n",
    "    def print_q(self):\n",
    "        for k,v in self.q.items():\n",
    "            print(k,v)\n",
    "    \n",
    "def minimax(state, depth, player):\n",
    "    \"\"\"\n",
    "    AI function that choice the best move\n",
    "    :param state: current state of the board\n",
    "    :param depth: node index in the tree (0 <= depth <= 9),\n",
    "    but never nine in this case (see iaturn() function)\n",
    "    :param player: an human or a computer\n",
    "    :return: a list with [the best row, best col, best score]\n",
    "    \"\"\"\n",
    "    if player == -1:\n",
    "        best = [-1, -1, -10000000]\n",
    "    else:\n",
    "        best = [-1, -1, +10000000]\n",
    "\n",
    "    if depth == 0 or gameWon(state):\n",
    "        score = getScore(state)\n",
    "        return [-1, -1, score]\n",
    "\n",
    "    for cell in blanks(state):\n",
    "        x, y = cell[0], cell[1]\n",
    "        state[x][y] = player\n",
    "        score = minimax(state, depth - 1, -player)\n",
    "        state[x][y] = 0\n",
    "        score[0], score[1] = x, y\n",
    "\n",
    "        if player == -1:\n",
    "            if score[2] > best[2]:\n",
    "                best = score  # max value\n",
    "        else:\n",
    "            if score[2] < best[2]:\n",
    "                best = score  # min value\n",
    "\n",
    "    return best\n",
    "\n",
    "def abminimax(board, depth, alpha, beta, player):\n",
    "    row = -1\n",
    "    col = -1\n",
    "    if depth == 0 or gameWon(board):\n",
    "        return [row, col, getScore(board)]\n",
    "\n",
    "    else:\n",
    "        for cell in blanks(board):\n",
    "            setMove(board, cell[0], cell[1], player)\n",
    "            score = abminimax(board, depth - 1, alpha, beta, -player)\n",
    "            if player == 1:\n",
    "                # X is always the max player\n",
    "                if score[2] > alpha:\n",
    "                    alpha = score[2]\n",
    "                    row = cell[0]\n",
    "                    col = cell[1]\n",
    "\n",
    "            else:\n",
    "                if score[2] < beta:\n",
    "                    beta = score[2]\n",
    "                    row = cell[0]\n",
    "                    col = cell[1]\n",
    "\n",
    "            setMove(board, cell[0], cell[1], 0)\n",
    "\n",
    "            if alpha >= beta:\n",
    "                break\n",
    "\n",
    "        if player == 1:\n",
    "            return [row, col, alpha]\n",
    "\n",
    "        else:\n",
    "            return [row, col, beta]\n",
    "\n",
    "def o_comp(board):\n",
    "    if len(blanks(board)) == 9:\n",
    "        #x = choice([0, 1, 2])\n",
    "        #y = choice([0, 1, 2])\n",
    "        move = minimax(board, len(blanks(board)), +1)\n",
    "        x, y = move[0], move[1]\n",
    "        setMove(board, x, y, -1)\n",
    "        Gameboard(board)\n",
    "\n",
    "    else:\n",
    "        result = abminimax(board, len(blanks(board)), -inf, inf, -1)\n",
    "        setMove(board, result[0], result[1], -1)\n",
    "        Gameboard(board)\n",
    "\n",
    "def x_comp(board):\n",
    "    if len(blanks(board)) == 9:\n",
    "        #x = choice([0, 1, 2])\n",
    "        #y = choice([0, 1, 2])\n",
    "        move = minimax(board, len(blanks(board)), +1)\n",
    "        x, y = move[0], move[1]\n",
    "        setMove(board, x, y, 1)\n",
    "        Gameboard(board)\n",
    "\n",
    "    else:\n",
    "        result = abminimax(board, len(blanks(board)), -inf, inf, 1)\n",
    "        setMove(board, result[0], result[1], 1)\n",
    "        Gameboard(board)\n",
    "\n",
    "def makeMove(board, player, mode):\n",
    "    if mode == 1:\n",
    "        if player == 1:\n",
    "            minimax(board,len(blanks(board)),player)\n",
    "\n",
    "        else:\n",
    "            o_comp(board)\n",
    "    else:\n",
    "        if player == 1:\n",
    "            o_comp(board)\n",
    "        else:\n",
    "            x_comp(board)\n",
    "\n",
    "def pvc():\n",
    "    currentPlayer = 1\n",
    "    \"\"\"while True:\n",
    "        try:\n",
    "            order = int(input('Enter to play 1st or 2nd: '))\n",
    "            if not (order == 1 or order == 2):\n",
    "                print('Please pick 1 or 2')\n",
    "            else:\n",
    "                break\n",
    "        except(KeyError, ValueError):\n",
    "            print('Enter a number')\n",
    "\n",
    "    Clearboard(board)\n",
    "    if order == 2:\n",
    "        currentPlayer = -1\n",
    "    else:\n",
    "        currentPlayer = 1\"\"\"\n",
    "\n",
    "    while not (boardFull(board) or gameWon(board)):\n",
    "        makeMove(board, currentPlayer, 1)\n",
    "        currentPlayer *= -1\n",
    "        makeMove(board, currentPlayer, -1)\n",
    "        currentPlayer *= 1\n",
    "\n",
    "    printResult(board)\n",
    "\n",
    "# Driver Code\n",
    "print(\"=================================================\")\n",
    "print(\"TIC-TAC-TOE using MINIMAX with MIN MAX OVER ALPHA-BETA Pruning\")\n",
    "print(\"=================================================\")\n",
    "pvc()  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc47c7ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f161fb5d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87744ece",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59a6e1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
